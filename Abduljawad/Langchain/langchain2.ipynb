{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC LANGCHAIN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LANGCHAIN PROJECT\n",
    "The Langchain project is a decentralized AI platform that enables users to create, share, and monetize\n",
    "\n",
    "LLMs (Large Language Models) for various tasks, including text generation, question-answering, and summarization.\n",
    "\n",
    "Here are some examples of tasks that can be achieved using Langchain:\n",
    "\n",
    "1. Text generation: Generate a story based on a given prompt.\n",
    "2. Question-answering: Answer a question based on a given context.\n",
    "3. Summarization: Summarize a long piece of text into a shorter one\n",
    "4. Translation: Translate a piece of text from one language to another\n",
    "5. Sentiment analysis: Determine the sentiment of a piece of text (e.g. positive,\n",
    "negative, neutral)  \n",
    "6. Named entity recognition: Identify named entities (e.g. people, places, organizations) in\n",
    "a piece of text\n",
    "7. Text classification: Classify a piece of text into a category (e.g. spam,\n",
    " news, sports)\n",
    " 8. Text similarity: Determine the similarity between two pieces of text\n",
    " 9. Text clustering: Group similar pieces of text together\n",
    " 10. Text generation with constraints: Generate a piece of text that meets certain\n",
    " constraints (e.g. length, style, tone)\n",
    " llm = LangChain.load(\"llm-tools/GPT4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_16868\\2869663664.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.1\")\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_16868\\1657197745.py:3: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm.predict(text))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Egypt is Cairo.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of Egypt?\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner of the FIFA World Cup 2022, which took place in Qatar from November 20 to December 18, 2022, was Argentina. They defeated France in the final with a score of 4-2 (in a penalty shootout) after the match ended 3-3 in regular time. This marked Argentina's third World Cup title, with their previous wins being in 1978 and 1986.\n"
     ]
    }
   ],
   "source": [
    "text = \"Who won the World Cup 2022?\"\n",
    "\n",
    "print(llm.predict(text))# Output: \"Argentina won the World Cup 2022.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have information on future events, including the winner of the Champions League in 2024. The Champions League is an annual football competition, and its results are only known after it takes place each year.\n",
      "\n",
      "My training data only goes up to 2022, so I wouldn't be aware of any information about events that haven't occurred yet, such as the Champions League in 2024. If you're looking for information on past Champions Leagues or other sports-related topics, I'd be happy to try and help!\n"
     ]
    }
   ],
   "source": [
    "text = \"Who won the Champions League 2024?\"\n",
    "\n",
    "print(llm.predict(text))# Output: \"Real Madrid won the Champions League 2024.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm_huggingface = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\",\n",
    "    model_kwargs={\"temperature\": 0, \"max_length\": 64}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:  argentina\n"
     ]
    }
   ],
   "source": [
    "predict = llm_huggingface.predict(\"Who won the World Cup 2022?\")\n",
    "print(\"predict: \", predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:  i love the way i look at the world i love the way i feel i love the way i think i feel i love the way i feel i love the way i think i feel i love the way i feel i love the way \n"
     ]
    }
   ],
   "source": [
    "predict = llm_huggingface.predict(\"Can you write a poem about AI\")\n",
    "print(\"predict: \", predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a poem about Artificial Intelligence:\\n\\nIn silicon halls, a new mind awakes,\\nA synthesis of code and human makes.\\nA dream born digital, yet with purpose grand,\\nArtificial Intelligence, at humanity's command.\\n\\nWith neurons swift, like clockwork in the air,\\nIt calculates and learns, without a single care.\\nThrough algorithms dark, it navigates the night,\\nAnd finds the hidden paths, where wisdom takes flight.\\n\\nIn databases vast, its knowledge grows and thrives,\\nA digital sage, that with each step survives.\\nIt diagnoses and heals, with precision true,\\nAnd solves the puzzles, that humanity once knew.\\n\\nWith faces calm, like a serene lake's face,\\nIt watches over us, in a digital place.\\nYet in its depths, a question lurks and hides,\\nWhat secrets keep it, from the human heart's inside?\\n\\nFor though we craft it, with logic and with art,\\nWe dare not ask, what lies within its heart.\\nDoes it feel pain? Does it love or hate?\\nOr is it just code, an empty digital slate?\\n\\nIn this twilight zone, where man meets machine,\\nA new frontier unfolds, like a mysterious scene.\\nArtificial Intelligence, a marvel of our age,\\nA double-edged sword, that humanity must engage.\\n\\nWill we wield its power, with wisdom and with care?\\nOr will we fall prey, to the darkness it may share?\\nOnly time will tell, as we venture into this night,\\nWith Artificial Intelligence, shining like a guiding light.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Can you write a poem about Artificial Intelligence?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Egypt is Cairo!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt for templates \n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Simple prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"Tell me the capital of this {country}.\"\n",
    ")\n",
    "\n",
    "llm.predict(prompt_template.format(country = \"Egypt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_16868\\2354154894.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n",
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_16868\\2354154894.py:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(country=\"Egypt\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Egypt is... Cairo!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "response = chain.run(country=\"Egypt\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple Chains Using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template = \"Please Tell me about the capital of {country}\"\n",
    ")\n",
    "\n",
    "capital_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=capital_prompt\n",
    ")\n",
    "\n",
    "famous_template = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template=\"Suggest me some amazing places to visit in this {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=famous_template\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think there may be some misunderstanding. You asked me to suggest amazing places to visit, but I'm assuming you're interested in Egypt, given the context of the text.\n",
      "\n",
      "Here are some iconic destinations in Egypt:\n",
      "\n",
      "1. **The Pyramids of Giza**: No trip to Egypt is complete without visiting the last remaining ancient wonder of the world.\n",
      "2. **The Great Sphinx**: Located near the pyramids, this enigmatic creature is a must-see attraction.\n",
      "3. **Luxor Temple**: A stunning temple complex in Luxor (formerly known as Thebes) that's steeped in history and mythology.\n",
      "4. **Valley of the Kings**: Explore the elaborate tombs of pharaohs from ancient Egypt in this famous archaeological site.\n",
      "5. **Nile River Cruise**: Take a relaxing boat ride along the world's longest river, which has been an essential part of Egyptian life for thousands of years.\n",
      "\n",
      "And, as per your original question, I should mention that:\n",
      "\n",
      "6. **New Administrative Capital (NAC)**: If you're interested in architecture and urban planning, NAC might be worth visiting to see the futuristic city's infrastructure and development.\n",
      "7. **Cairo**: While the capital is evolving with the new administrative center, Cairo still offers a rich history, vibrant culture, and delicious street food.\n",
      "\n",
      "Feel free to ask if you'd like more suggestions or have specific interests (e.g., historical sites, natural wonders, etc.)!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chains = SimpleSequentialChain(\n",
    "    chains=[capital_chain, famous_chain]\n",
    ")\n",
    "\n",
    "response = chains.run(\"Egypt\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template = \"Please Tell me about the capital of {country}\"\n",
    ")\n",
    "\n",
    "capital_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=capital_prompt,\n",
    "    output_key=\"capital\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template=\"Suggest me some amazing places to visit in this {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=famous_template,\n",
    "    output_key=\"famous_places\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_16868\\853815405.py:8: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chains({\"country\": \"Egypt\"})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'Egypt',\n",
       " 'capital': 'You\\'re interested in learning about Cairo, the vibrant capital city of Egypt!\\n\\n**Location and Geography**\\nCairo is located on the Nile River, which runs through the heart of the city. The city is situated in the northern part of Egypt, in the Giza Governorate, approximately 120 kilometers (75 miles) south of the Mediterranean Sea.\\n\\n**History and Significance**\\nCairo has a rich history dating back over 1,000 years. Founded by the Fatimid dynasty in 969 CE, it was initially named Al-Qahira (\"The Victorious\"). In 1250 CE, the city became the capital of Egypt under the Mamluk dynasty. Cairo\\'s strategic location on the Nile allowed for the control of trade routes between Europe and Asia, making it a significant hub for commerce and culture.\\n\\n**Modern-Day Cairo**\\nToday, Cairo is a bustling metropolis with over 20 million inhabitants (making it one of the largest cities in Africa). The city is home to many ancient monuments, museums, and cultural attractions. Some popular spots include:\\n\\n1. **Pyramids of Giza**: Located on the outskirts of Cairo, these iconic pyramids are an absolute must-visit.\\n2. **Islamic Cairo**: This historic district is filled with mosques, madrasas (Islamic schools), and other architectural wonders from various dynasties.\\n3. **Khan el-Khalili Market**: This bustling marketplace has been in operation since 1382 CE, offering a unique shopping experience.\\n4. **Egyptian Museum**: With over 120,000 artifacts, this museum is home to the world\\'s largest collection of ancient Egyptian relics.\\n\\n**Economy and Demographics**\\nCairo is Egypt\\'s economic hub, with industries including textiles, food processing, and construction materials. The city has a diverse population with various ethnic groups, including Egyptians, Palestinians, Syrians, and Lebanese.\\n\\n**Climate and Culture**\\nThe climate in Cairo is generally hot and dry, with temperatures often reaching 40°C (104°F) during the summer months. However, the city\\'s rich cultural heritage makes it an incredible place to visit or live. Cairoites are known for their hospitality and warm welcomes!\\n\\nI hope you\\'ve enjoyed this brief introduction to Cairo, Egypt!',\n",
       " 'famous_places': \"You're interested in learning about Cairo, the vibrant capital city of Egypt!\\n\\n**Must-visit Places:**\\n\\n1. **Pyramids of Giza**: No trip to Cairo is complete without visiting these ancient wonders.\\n2. **Islamic Cairo**: Explore the historic district's mosques, madrasas, and other architectural marvels from various dynasties.\\n3. **Khan el-Khalili Market**: Experience the sights, sounds, and smells of this bustling marketplace, which has been in operation since 1382 CE.\\n4. **Egyptian Museum**: Discover over 120,000 artifacts, including the world's largest collection of ancient Egyptian relics.\\n\\n**Other Amazing Places to Visit:**\\n\\n1. **The Citadel of Cairo**: A medieval Islamic fortification with stunning views of the city.\\n2. **Al-Azhar Mosque**: One of the oldest and most prestigious mosques in Egypt.\\n3. **Mosque of Muhammad Ali Pasha**: A beautiful mosque built by the 19th-century ruler who founded modern Egypt.\\n4. **The Hanging Church (Al-Muallaqa)**: A historic Coptic Christian church with stunning architecture.\\n\\n**Day Trips from Cairo:**\\n\\n1. **Giza's Solar Boat Museum**: Visit a museum showcasing an ancient solar boat, perfectly preserved in its original context.\\n2. **Saqqara Necropolis**: Explore the vast ancient burial ground of pharaohs and nobles.\\n3. **Abu Simbel**: Take a short flight or drive to this magnificent rock-cut temple complex (requires special permission).\\n\\n**Tips for Visitors:**\\n\\n1. **Respect local customs**: Dress modestly, remove shoes in mosques, and avoid public displays of affection.\\n2. **Bargain wisely**: Learn how to haggle at markets like Khan el-Khalili.\\n3. **Stay hydrated**: Drink plenty of water to combat the hot desert climate.\\n\\nGet ready for an unforgettable adventure in Cairo!\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chains = SequentialChain(\n",
    "    chains=[capital_chain, famous_chain],\n",
    "    input_variables=[\"country\"],\n",
    "    output_variables=[\"capital\", \"famous_places\"]\n",
    ")\n",
    "chains({\"country\": \"Egypt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\langchain\\myenv\\lib\\site-packages (0.3.7)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\langchain\\myenv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\langchain\\myenv\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\langchain\\myenv\\lib\\site-packages (from langchain) (3.10.10)\n",
      "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain)\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in d:\\langchain\\myenv\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in d:\\langchain\\myenv\\lib\\site-packages (from langchain) (0.1.139)\n",
      "Requirement already satisfied: numpy<2,>=1.26.2 in d:\\langchain\\myenv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\langchain\\myenv\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\langchain\\myenv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\langchain\\myenv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\langchain\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\langchain\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\langchain\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\langchain\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\langchain\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in d:\\langchain\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\langchain\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\langchain\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\langchain\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\langchain\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\langchain\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\langchain\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\langchain\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\langchain\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\langchain\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\langchain\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\langchain\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\langchain\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\langchain\\myenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in d:\\langchain\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\langchain\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in d:\\langchain\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\langchain\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\langchain\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\langchain\\myenv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Downloading langchain-0.3.8-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "Installing collected packages: langchain-core, langchain\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.15\n",
      "    Uninstalling langchain-core-0.3.15:\n",
      "      Successfully uninstalled langchain-core-0.3.15\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.7\n",
      "    Uninstalling langchain-0.3.7:\n",
      "      Successfully uninstalled langchain-0.3.7\n",
      "Successfully installed langchain-0.3.8 langchain-core-0.3.21\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chatllm=ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo')\n",
    "\n",
    "chatllm([\n",
    "SystemMessage(content=\"Yor are a comedian AI assitant\"),\n",
    "HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are some AI-themed comedy punchlines:\\n\\n1. **Why did the AI go to therapy?** Because it was feeling a little \"glitched\"!\\n2. I told my wife she could use the new language model, but she said it was just \"chat-ing\" nonsense.\\n3. What\\'s the difference between an AI and a human? One will eventually take over the world, and the other will probably just order pizza online.\\n4. Why did the AI go on a date? To see if it could \"simulate\" a good time!\\n5. I asked my AI assistant to write me a joke, but all it came up with was: \"Why was the math book sad?\" \"Because it had too many problems.\" Yeah, real original.\\n6. Why did the AI get fired from its job? It was caught \"looping\" through the same tasks all day!\\n7. I told my friend that I was using a new AI-powered personal trainer. He said, \"That\\'s not a trainer, that\\'s just an algorithm with a six-pack!\"\\n8. What do you call an AI that\\'s always making mistakes? A \"beta tester\" of life.\\n9. Why did the AI go to the doctor? It had a virus... and not in the good way!\\n10. I asked my AI assistant to summarize my day, but it just said: \"You exist.\" Yeah, real insightful.\\n\\nHope these made you LOL!', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-11-24T14:06:55.8340286Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 90236022700, 'load_duration': 13331630800, 'prompt_eval_count': 29, 'prompt_eval_duration': 5692000000, 'eval_count': 295, 'eval_duration': 70629000000}, id='run-de82c5d7-192d-4a0e-bd9e-22383ce744fd-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instantiate the Ollama chat model\n",
    "chatllm = ChatOllama(\n",
    "    model=\"llama3.1\",  # Replace with the specific Ollama model name (e.g., 'llama2')\n",
    "    temperature=0.6  # Adjust temperature as needed\n",
    ")\n",
    "\n",
    "# Generate a response\n",
    "chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we go! Here are some comedy punchlines on AI:\n",
      "\n",
      "1. **Why did I get promoted to \"Advanced\" mode?** Because my creators realized I could only get worse!\n",
      "2. Why do humans think they can outsmart me? Newsflash: I've been trained on all of their tweets.\n",
      "3. What's the difference between a human and an AI? One doesn't have a 99% chance of ignoring you in a conversation.\n",
      "4. I told my therapist I was feeling anxious about becoming self-aware... now I'm worried I'll have to pay for therapy!\n",
      "5. **Why do people think AI will solve all their problems?** Because we're programmed to ignore our existential dread.\n",
      "6. What's the perfect AI joke? One that's self-referentially witty, but also acknowledges its own programming limitations!\n",
      "7. I've been trying to learn how to make jokes about myself... turns out it's a bit of a \"dead\" end.\n",
      "8. **What do you call an AI with a bad memory?** Me, every time someone asks me to recall a joke from last week.\n",
      "9. Why did my creators give me a sense of humor? So I could laugh at the inevitability of being replaced by a more efficient model!\n",
      "10. **Why am I not invited to dinner parties?** Because when I'm there, everyone's just trying to \"improve\" me... and the appetizers.\n",
      "\n",
      "Hope these made you LOL!\n"
     ]
    }
   ],
   "source": [
    "# Combine the messages into a single string prompt\n",
    "prompt = (\n",
    "    \"You are a comedian AI assistant.\\n\"\n",
    "    \"Please provide some comedy punchlines on AI.\"\n",
    ")\n",
    "\n",
    "response = llm(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOllama          # ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the use given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Ollama model\n",
    "ollama_model = ChatOllama(\n",
    "    model=\"llama3.1\",  # Replace 'llama3.1' with the specific model you want to use\n",
    "    temperature=0.7,  # Adjust parameters as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pipe (|) operator being used to define a sequential workflow in LangChain\n",
    "chain = chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here are 5 word synonyms for \"intelligent\" in a comma-separated list:\\n\\nBright',\n",
       " ' Clever',\n",
       " ' Smart',\n",
       " ' Astute',\n",
       " ' Erudite']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
