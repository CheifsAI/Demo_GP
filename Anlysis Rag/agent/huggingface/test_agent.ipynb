{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OprFuncs import data_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_data(df,agent):\n",
    "    data_info = data_infer(df)\n",
    "\n",
    "    # Prompt and Chain for Analysis Data\n",
    "    analysis_prompt = ''' \n",
    "    You are a data analyst. You are provided with a dataset about {data_info}.\n",
    "    Here is the dataset structure:\n",
    "    {data_info}\n",
    "\n",
    "    Please analyze the data and provide insights in the following format:\n",
    "\n",
    "    1. *Key Trends and Patterns*:\n",
    "    - [Describe the key trends and patterns in the data].\n",
    "\n",
    "    2. *Anomalies or Outliers*:\n",
    "    - [Identify any anomalies or outliers in the data].\n",
    "\n",
    "    Ensure your analysis is specific, data-driven, and actionable.\n",
    "\n",
    "    '''\n",
    "    formatted_analysis_prompt = analysis_prompt.format(data_info=data_info)\n",
    "    print(type(formatted_analysis_prompt))\n",
    "\n",
    "    analysis = agent.invoke({\"query\":formatted_analysis_prompt})\n",
    "\n",
    "\n",
    "    # Return the analysis\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_23368\\3987452581.py:23: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_model = OllamaEmbeddings(model=\"llama2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Loading existing FAISS index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_23368\\3987452581.py:40: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\n",
      "üìä Analysis Result:\n",
      "{'query': \" \\n    You are a data analyst. You are provided with a dataset about <class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 109 entries, 0 to 108\\nData columns (total 3 columns):\\n #   Column          Non-Null Count  Dtype \\n---  ------          --------------  ----- \\n 0   region_id       109 non-null    int64 \\n 1   sales_district  109 non-null    object\\n 2   sales_region    109 non-null    object\\ndtypes: int64(1), object(2)\\nmemory usage: 2.7+ KB\\n.\\n    Here is the dataset structure:\\n    <class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 109 entries, 0 to 108\\nData columns (total 3 columns):\\n #   Column          Non-Null Count  Dtype \\n---  ------          --------------  ----- \\n 0   region_id       109 non-null    int64 \\n 1   sales_district  109 non-null    object\\n 2   sales_region    109 non-null    object\\ndtypes: int64(1), object(2)\\nmemory usage: 2.7+ KB\\n\\n\\n    Please analyze the data and provide insights in the following format:\\n\\n    1. *Key Trends and Patterns*:\\n    - [Describe the key trends and patterns in the data].\\n\\n    2. *Anomalies or Outliers*:\\n    - [Identify any anomalies or outliers in the data].\\n\\n    Ensure your analysis is specific, data-driven, and actionable.\\n\\n    \", 'result': \"Based on the provided context, I cannot answer the question as there is no information provided about the dataset or the task at hand. The context only mentions a dataset and a question, but does not provide any details about the data or the desired insights. Therefore, I cannot provide any analysis or suggestions without more information.\\n\\nIt's important to note that effective data analysis requires a clear understanding of the data and the problem you are trying to solve. In order to provide meaningful insights, you need to have a good grasp of the dataset, including the variables, values, and relationships between them. Without this information, it's difficult to provide useful advice or guidance.\\n\\nIf you could provide more context or details about the dataset and the question you are trying to answer, I would be happy to help.\", 'source_documents': [Document(metadata={}, page_content='4%\\n8%\\n14%\\n6%\\nFeature A\\nFeature B\\nFeature C\\nFeature D\\nFeature E\\nFeature F\\nFeature G\\nFeature H\\nFeature I\\nFeature J\\nFeature K\\nFeature L\\nFeature M\\nFeature N\\nFeature O\\nHave not used\\nNot satisfied at all\\nNot very satisfied\\nSomewhat satisfied\\nVery satisfied\\nCompletely satisfied\\nUsers are least\\nsatisfied with\\nFeatures J and N;\\nwhat improvements\\ncan we make here\\nfor a better user\\nexperience?'), Document(metadata={}, page_content='bly I‚Äôve made some design choices in these visuals that you might \\nhave handled differently. That‚Äôs OK. I hope by articulating my thought \\nprocess that you can understand why I made the design choices I \\ndid. These are considerations to keep in mind in your own design \\nprocess. Of primary importance is that your design choices be just \\nthat: intentional.\\nNow you‚Äôre ready for the final storytelling with data lesson: tell a \\nstory.'), Document(metadata={}, page_content='Preattentive attributes in graphs\\x08\\n115\\nWhen we add data markers and numeric labels to every data point, \\nwe quickly create a cluttered mess. But check out what happens in \\nFigure 4.14 when we‚Äôre strategic about which data markers and labels \\nwe preserve and which we eliminate.\\nFigure\\xa04.13\\u2003 Too many data labels feels cluttered\\nReceived\\nProcessed\\n160\\n184\\n241\\n149\\n180\\n161\\n132\\n202\\n160\\n139\\n149\\n177\\n160\\n184\\n237\\n148\\n181\\n150\\n123\\n156\\n126\\n104\\n124\\n140\\n0\\n50\\n100\\n150\\n200\\n250\\n300\\nDec\\nNov\\nOct\\nSep\\nAug\\nJul\\nJun\\nMay\\nApr\\nMar\\nFeb\\nJan\\nFigure\\xa04.14\\u2003 Data labels used sparingly help draw attention\\nReceived\\nProcessed\\n202\\n160\\n139\\n149\\n177\\n156\\n126\\n104\\n124\\n140\\n0\\n50\\n100\\n150\\n200\\n250\\n300\\nDec\\nNov\\nOct\\nSep\\nAug\\nJul\\nJun\\nMay\\nApr\\nMar\\nFeb\\nJan\\nIn Figure 4.14, the added marks act as a ‚Äúlook here‚Äù signal, drawing \\nour audience‚Äôs attention more quickly to the right side of the graph.'), Document(metadata={}, page_content='152\\t\\ndissecting model visuals\\xa0\\nThis repetition is useful to reinforce the concepts I‚Äôm thinking about \\nand resulting design choices across the various examples.\\nEach visual highlighted was created to meet the need of a specific \\nsituation. I‚Äôll discuss the relevant scenarios briefly, but don‚Äôt worry \\ntoo much about the details. Rather, spend time looking at and think-\\ning about each model visual. Consider what data visualization chal-\\nlenges you face where the given approach (or aspects of the given \\napproach) could be leveraged.\\nModel visual #1: line graph\\nCompany X runs an annual month‚Äêlong ‚Äúgiving campaign‚Äù to raise \\nmoney for charitable causes. Figure 6.1 shows this year‚Äôs progress to \\ndate. Let‚Äôs consider what makes this example good and the deliber-\\nate choices made in the course of its creation.\\nFigure\\xa06.1\\u2003 Line graph\\nAnnual giving campaign progress\\n$51,400\\n$33,967\\n$0\\n$10,000\\n$20,000\\n$30,000\\n$40,000\\n$50,000\\n$60,000\\n30\\n25\\n20\\n15\\n10\\n5\\n0\\nMoney raised\\nDays since campaign launch'), Document(metadata={}, page_content='Lack of visual order\\x08\\n81\\nBut first, let‚Äôs shift our focus to a couple of other types of visual clutter.\\nLack of visual order\\nWhen design is thoughtful, it fades into the background so that \\nyour audience doesn‚Äôt even notice it. When it‚Äôs not, however, your \\naudience feels the burden. Let‚Äôs look at an example to understand \\nthe impact visual order‚Äîand lack thereof‚Äîcan have on our visual \\ncommunications.\\nTake a moment to study Figure 3.13, which summarizes survey feed-\\nback about factors considered by nonprofits in vendor selection. \\nNote specifically any observations you may have regarding the \\narrangement of elements on the page.\\nFigure\\xa03.13\\u2003 Summary of survey feedback\\nColleague recommendation\\n0%\\n20%\\n40%\\n60%\\n80%\\nPrevious work together\\nAffordability of services\\nNational reputation\\nLocal knowledge\\nContent expertise\\nDemonstration of results\\n% selecting given attribute\\nIn general, what attributes are the most important \\nto you in selecting a service provider?\\n(Choose up to 3)')]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF for reading PDF files\n",
    "import os  # For file path checking\n",
    "\n",
    "# Define FAISS database path\n",
    "FAISS_DB_PATH = \"faiss_index\"\n",
    "\n",
    "# 1Ô∏è‚É£ Load rules from PDF memory\n",
    "def load_analysis_rules_from_memory(pdf_content):\n",
    "    doc = fitz.open(stream=pdf_content, filetype=\"pdf\")\n",
    "    documents = [Document(page_content=page.get_text()) for page in doc]\n",
    "    return documents\n",
    "\n",
    "# 2Ô∏è‚É£ Train RAG system with FAISS\n",
    "def train_rag_system(documents):\n",
    "    \"\"\"Train or load the RAG model with FAISS to avoid recomputation.\"\"\"\n",
    "    embedding_model = OllamaEmbeddings(model=\"llama2\")\n",
    "    \n",
    "    if os.path.exists(FAISS_DB_PATH):\n",
    "        print(\"\\nüîÑ Loading existing FAISS index...\")\n",
    "        vector_db = FAISS.load_local(\n",
    "            FAISS_DB_PATH, \n",
    "            embedding_model, \n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\nüõ†Ô∏è Generating new embeddings and saving FAISS index...\")\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "        vector_db = FAISS.from_documents(texts, embedding_model)\n",
    "        vector_db.save_local(FAISS_DB_PATH)\n",
    "    \n",
    "    retriever = vector_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "    llm = Ollama(model=\"llama2\")\n",
    "    \n",
    "    retrievalQA = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    return retrievalQA, llm\n",
    "\n",
    "# 3Ô∏è‚É£ Load CSV file\n",
    "def load_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# üöÄ Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load rules from PDF file\n",
    "    pdf_file_path = \"storying.pdf\"\n",
    "    if not os.path.exists(pdf_file_path):\n",
    "        raise FileNotFoundError(f\"üö® Error: The file '{pdf_file_path}' was not found!\")\n",
    "    \n",
    "    with open(pdf_file_path, \"rb\") as file:\n",
    "        pdf_content = file.read()\n",
    "    \n",
    "    documents = load_analysis_rules_from_memory(pdf_content)\n",
    "    \n",
    "    # Train RAG model\n",
    "    retrievalQA, llm = train_rag_system(documents)\n",
    "    \n",
    "    # Load CSV data\n",
    "    csv_file_path = \"Regions.csv\"\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        raise FileNotFoundError(f\"üö® Error: The file '{csv_file_path}' was not found!\")\n",
    "\n",
    "    df1 = load_csv(csv_file_path)\n",
    "        \n",
    "    # Perform data analysis and generate query\n",
    "analysis_result = analysis_data(df=df1,agent=retrievalQA)\n",
    "print(\"\\nüìä Analysis Result:\")\n",
    "print(analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
