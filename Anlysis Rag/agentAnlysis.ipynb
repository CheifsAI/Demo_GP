{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.agents import Tool, AgentExecutor, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def retrieval(information):\n",
    "\n",
    "    FAISS_DB_PATH = \"faiss_KPIS\"\n",
    "\n",
    "    embedding_model = OllamaEmbeddings(model=\"llama3.2:3b\")\n",
    "    print(\"\\nðŸ”„ Loading existing FAISS index...\")\n",
    "    vector_db = FAISS.load_local(\n",
    "        FAISS_DB_PATH, \n",
    "        embedding_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "\n",
    "    retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "    llm = Ollama(model=\"llama3.2:3b\")\n",
    "        \n",
    "        # Define custom prompt using PromptTemplate\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"information\"],\n",
    "        template=\"\"\"\n",
    "        Use the following piece of {information} to provide the proper KPI to use\n",
    "        \n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    retrievalQA = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt_template} \n",
    "    )\n",
    "\n",
    "    return retrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain_community.llms import Ollama\n",
    "from OprFuncs import data_infer, extract_code, extract_questions\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Ollama\n",
    "llm = Ollama(model=\"llama3.2:3b\")\n",
    "docx_file_path = \"kpis.docx\"\n",
    "if not os.path.exists(docx_file_path):\n",
    "    raise FileNotFoundError(f\"ðŸš¨ Error: The file '{docx_file_path}' was not found!\")\n",
    "\n",
    "documents = load_analysis_rules_from_memory(docx_file_path)\n",
    "    \n",
    "retrievalQA = train_rag_system(documents)\n",
    "dataframe = pd.read_csv(\"Test_Datasets/supply_chain_data.csv\")\n",
    "\n",
    "tools = [\n",
    "\n",
    "    Tool(\n",
    "        name=\"understander\",\n",
    "        func=understander,  \n",
    "        description=\"Provide usable information.\"\n",
    "        )\n",
    "    Tool(\n",
    "        name=\"retrieval\",\n",
    "        func=retrieval,  \n",
    "        description=\"Use this tool to provide a kpi based on the information.\"\n",
    "        )\n",
    "    Tool(\n",
    "        name=\"analyzer\",\n",
    "        func=analysis_data,  \n",
    "        description=\"Use this tool anlysis the dataframe using the kpi from the retrival tool.\"\n",
    "        )\n",
    "]\n",
    "agent_prompt = hub.pull(\"hwchase17/react\").partial(\n",
    "    instructions=\"\"\"Follow EXACTLY this sequence:\n",
    "    1. Use understander ONCE\n",
    "    2. Use retrieval ONCE\n",
    "    3. Use analyzer ONCE\n",
    "    NEVER repeat steps or tools\"\"\"\n",
    ")\n",
    "agent = create_react_agent(llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    handle_parsing_errors=True,\n",
    "    stop=[\"\\nFINAL ANSWER\"] \n",
    ")\n",
    "\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": f\"\"\"Analyze this question and generate visualization code:\n",
    "    Question: {question}\n",
    "    Follow this EXACT format:\n",
    "    Thought: First analyze the question\n",
    "    Action: ChartSelector\n",
    "    Action Input: \"{question}\"\n",
    "    Observation: [chart-type]\n",
    "    Thought: Now generate code\n",
    "    Action: CodeGenerator\n",
    "    Action Input: \"{question}|[chart-type]\"\n",
    "    FINAL ANSWER:\"\"\"\n",
    "})\n",
    "\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def understander(df,llm):\n",
    "    data_info = data_infer(df)\n",
    "\n",
    "    understanding_prompt = ''' \n",
    "    You are a data analyst. You are provided with a dataset about {data_info}.\n",
    "    Here is the dataset structure:\n",
    "    {data_info}\n",
    "\n",
    "    Please understand what's the data about, you will provide 1 information in order to create the KPI, \n",
    "    return only the information about the data (what's data about, what column or relation you want to create the KPI for)\n",
    "\n",
    "    '''\n",
    "\n",
    "    understanding_chain = LLMChain(llm=llm, prompt=understanding_prompt)\n",
    "\n",
    "        \n",
    "    understanding = understanding_chain.run(data_info=data_info)\n",
    "\n",
    "    return understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_describer(dataframe):\n",
    "    # Get the description of the dataframe\n",
    "    description = dataframe.describe()\n",
    "    \n",
    "    # Convert the description to a string with column names\n",
    "    description_str = \"Data Description:\\n\"\n",
    "    for col in description.columns:\n",
    "        description_str += f\"\\nColumn: {col}\\n\"\n",
    "        description_str += description[col].to_string() + \"\\n\"\n",
    "    \n",
    "    # Write the description to a file\n",
    "    with open(\"df_description.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(description_str)\n",
    "    \n",
    "    return description_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = dataframe.head().to_string\n",
    "data_summary = data_describer(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_data(df,llm):\n",
    "    data_info = data_infer(df)\n",
    "    data_sample = dataframe.head().to_string\n",
    "    data_summary = data_describer(dataframe)\n",
    "\n",
    "    analysis_prompt = '''\n",
    "        You are a data analyst. You are provided with:\n",
    "        1. Dataset metadata: {data_info}\n",
    "        2. Dataset sample: {data_sample}\n",
    "        3. Dataset summary: {data_summary} \n",
    "        4. KPIs:{kpi}\n",
    "\n",
    "        Please analyze the data and provide insights about:\n",
    "        Key trends and patterns using the {kpi}.\n",
    "        '''\n",
    "    analysis_template = PromptTemplate(\n",
    "            input_variables=[\"data_info\",\"data_sample\",\"data_summary\",\"kpi\"],\n",
    "            template=analysis_prompt\n",
    "        )\n",
    "        \n",
    "    analysis_chain = LLMChain(llm=llm, prompt=analysis_template)\n",
    "\n",
    "        \n",
    "    analysis = analysis_chain.run(data_info=data_info,data_sample=data_sample,data_summary=data_summary,kpi=kpi)\n",
    "\n",
    "\n",
    "    return analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
